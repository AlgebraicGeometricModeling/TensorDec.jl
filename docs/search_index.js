var documenterSearchIndex = {"docs":
[{"location":"code/3.decompose/#Decomposition","page":"Decomposition","title":"Decomposition","text":"","category":"section"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"Pages = [\"3.decompose.md\"]","category":"page"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"TensorDec.decompose ","category":"page"},{"location":"code/3.decompose/#MultivariateSeries.decompose","page":"Decomposition","title":"MultivariateSeries.decompose","text":"decompose(p :: DynamicPolynomials.Polynomial,  rkf :: Function)\n\nDecompose the homogeneous polynomial p as  ω_i (ξ_i1 x_1 +  + ξ_in x_n)ᵈ where d is the degree of p.\n\nThe optional argument rkf is the rank function used to determine the numerical rank from the vector S of singular values. Its default value eps_rkf(1.e-6) determines the rank as the first i s.t. S[i+1]/S[i]< 1.e-6 where S is the vector of singular values.\n\nIf the rank function cst_rkf(r) is used, the SVD is truncated at rank r.\n\n\n\n\n\ndecompose(T :: Array{C,3},  rkf :: Function)\n\nDecompose the multilinear tensor T of order 3 as a weighted sum of tensor products of vectors of norm 1.\n\nThe optional argument rkf is the rank function used to determine the numerical rank from the vector S of singular values. Its default value eps_rkf(1.e-6) determines the rank as the first i s.t. S[i+1]/S[i]< 1.e-6 where S is the vector of singular values.\n\nIf the rank function cst_rkf(r) is used, the SVD is truncated at rank r.\n\nSlices along the mode m=1 of the tensor (i.e. T[i,:,:]) are used by default to compute the decomposition. The optional argument mode = m can be used to specify the sliced mode.\n\ndecompose(T, mode=2)\ndecompose(T, eps_rkf(1.e-10), mode=3)\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"TensorDec.spm_decompose","category":"page"},{"location":"code/3.decompose/#TensorDec.spm_decompose","page":"Decomposition","title":"TensorDec.spm_decompose","text":"spm_decompose(T, r::Int64, v0::Vector)\n\nDecomposition of the tensor T in rank r with the Power Method.\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"TensorDec.rcg_decompose","category":"page"},{"location":"code/3.decompose/#TensorDec.rcg_decompose","page":"Decomposition","title":"TensorDec.rcg_decompose","text":"rcg_decompose(p :: Polynomial{true,T},  rkf :: Function)\n\nDecompose the homogeneous polynomial p as  ω_i (ξ_i1 x_1 +  + ξ_in x_n)ᵈ where d is the degree of p.\n\nThe optional argument rkf is the rank function used to determine the numerical rank from the vector S of singular values. Its default value eps_rkf(1.e-6) determines the rank as the first i s.t. S[i+1]/S[i]< 1.e-6 where S is the vector of singular values.\n\nIf the rank function cst_rkf(r) is used, the SVD is truncated at rank r.\n\nA Riemannian conjugate gradient algorithm is used (RCG) in the algorithm decompose (rcg_decompose) to approximate the pencil of submatrices of the Hankel matrix by a pencil of real simultaneous diagonalizable matrices.\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"TensorDec.tensorsplit","category":"page"},{"location":"code/3.decompose/#TensorDec.tensorsplit","page":"Decomposition","title":"TensorDec.tensorsplit","text":"Decompose V as u otimes v where u is of dimension n1 and v of dimension n2.\n\nIt is based on the svd decomposition of the n1 times n2 matrix associated to V.\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"TensorDec.approximate","category":"page"},{"location":"code/3.decompose/#TensorDec.approximate","page":"Decomposition","title":"TensorDec.approximate","text":"approximate(P::Polynomial, r:: Int64; iter = :RNE, init = :Random)\n\nThis function approximates a symmetric tensor (real or complex valued) into a low rank symmetric tensor.\n\nInput:\n\nP: The homogeneous polynomial associated to the symmetric tensor to approximate.\nr: Approximation rank.\n\nThe option iter specifies the method to apply in order to find the approximation, there are 4 options (the default is rnentr):\n\n * RNE: To apply the function 'rne_n_tr': This function gives a low symmetric rank approximation of a complex valued\n symmetric tensor by applying an exact Riemannian Newton iteration with\n dog-leg trust region steps to the associate non-linear-least-squares\n problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form\n of linear combination of r linear forms to the d-th power ``∑w_i*(v_i^tx)^d`` with i=1,...,r.\n This approximation is represented by a vector of strictly positive real numbers W=(w_i) (weight vector), and a matrix of normalized columns V=[v_1;...;v_r];\n\n * RNER: To apply the function 'rne_n_tr_r'(when the symmetric tensor is real and the symmetric tensor approximation is required to be real): This function gives a low symmetric rank approximation of a real valued\n symmetric tensor by applying an exact Riemannian Newton iteration with\n dog-leg trust region steps to the associate non-linear-least-squares\n problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form\n of linear combination of r linear forms to the d-th power ∑w_i*(v_i^tx)^d, with i=1,...,r.\n This approximation is represented by a vector of r real numbers W=(w_i) (weight vector), and a matrix\n of real normalized columns V=[v_1;...;v_r];\n\n * RGN: To apply the function 'rgn_v_tr': This function gives a low symmetric rank approximation of a complex valued\n symmetric tensor by applying a Riemannian Gauss-Newton iteration with\n dog-leg trust region steps to the associate non-linear-least-squares\n problem. The optimization set is a cartesian product of Veronese\n manifolds. The approximation is of the form\n of linear combination of r linear forms to the d-th power ∑(v_i^tx)^d, with i=1,...,r.\n This approximation is represented by a matrix [v_1;...;v_r];\n\n * SPM: To apply the function 'spm_decompose': Decomposition of the tensorwith the Power Method.\n\nThe option init specifies the way the initial point for the first three methods is chosen by the function decompose:\n\n * Random: To choose a random combination (default option);\n * Rnd: To choose non-random combination.\n *RCG: To choose to approximate the pencil of submatrices of the Hankel matrix by a pencil of real simultaneous diagonalizable matrices using Riemannian conjugate gradient algorithm.\n\n\n\n\n\napproximate(P::Polynomial, w0, V0; iter = :RNE, init = :Random)\n\nThis function approximates a symmetric tensor (real or complex valued) into a low rank symmetric tensor starting from an initial decomposition (w0, V0)\n\nInput:\n\nP: The homogeneous polynomial associated to the symmetric tensor to approximate.\nw0: Initial weights of the decomposition\nV0: Initial vectors of the decomposition\n\nThe option iter specifies the method to apply in order to find the approximation, there are 4 options (the default is :RNE):\n\n * RNE: To apply the function 'rne_n_tr': This function gives a low symmetric rank approximation of a complex valued\n symmetric tensor by applying an exact Riemannian Newton iteration with\n dog-leg trust region steps to the associate non-linear-least-squares\n problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form\n of linear combination of r linear forms to the d-th power ``∑w_i*(v_i^tx)^d`` with i=1,...,r.\n This approximation is represented by a vector of strictly positive real numbers W=(w_i) (weight vector), and a matrix of normalized columns V=[v_1;...;v_r];\n\n * RNER: To apply the function 'rne_n_tr_r'(when the symmetric tensor is real and the symmetric tensor approximation is required to be real): This function gives a low symmetric rank approximation of a real valued\n symmetric tensor by applying an exact Riemannian Newton iteration with\n dog-leg trust region steps to the associate non-linear-least-squares\n problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form\n of linear combination of r linear forms to the d-th power ∑w_i*(v_i^tx)^d, with i=1,...,r.\n This approximation is represented by a vector of r real numbers W=(w_i) (weight vector), and a matrix\n of real normalized columns V=[v_1;...;v_r];\n\n * RGN: To apply the function 'rgn_v_tr': This function gives a low symmetric rank approximation of a complex valued\n symmetric tensor by applying a Riemannian Gauss-Newton iteration with\n dog-leg trust region steps to the associate non-linear-least-squares\n problem. The optimization set is a cartesian product of Veronese\n manifolds. The approximation is of the form\n of linear combination of r linear forms to the d-th power ∑(v_i^tx)^d, with i=1,...,r.\n This approximation is represented by a matrix [v_1;...;v_r];\n\n * SPM: To apply the function 'spm_decompose': Decomposition of the tensorwith the Power Method.\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"TensorDec.rne_n_tr\nTensorDec.rne_n_tr_r\nTensorDec.rgn_v_tr","category":"page"},{"location":"code/3.decompose/#TensorDec.rne_n_tr","page":"Decomposition","title":"TensorDec.rne_n_tr","text":"rne_n_tr(P, A0, B0, Dict{String,Any}(\"maxIter\" => N,\"epsIter\" => ϵ))⤍ A, B, Info\n\nThis function gives a low symmetric rank approximation of a complex valued symmetric tensor by applying an exact Riemannian Newton iteration with dog-leg trust region steps to the associate non-linear-least-squares problem. The optimization set is parameterized by weights and unit vectors. Let r be the approximation rank. The approximation is of the form of linear combination of r linear forms to the d-th power w_i*(v_i^tx)^d with i=1,...,r. This approximation is represented by a vector of strictly positive real numbers W=(wi) (weight vector), and a matrix of normalized columns V=[v1;...;v_r].\n\nInput:\n\nP: Homogeneous polynomial (associated to the symmetric tensor to approximate).\nA0: Initial weight vector of size equal to the approximation rank.\nB0: Initial matrix of row size equal to the dimension of P and column size equal to the  approximation rank.\nN: Maximal number of iterations (by default 500).\nϵ: The radius of the trust region (by default 1.e-3).\n\nOutput:\n\nA: Weight vector of size equal to the approximation rank. It is a real strictly positive vector.\nB: Matrix of row size equal to the dimension of P and column size equal to the approximation rank. The columns vectors of B are normalized.\nInfo: 'd0' (resp. 'd*') represents the initial (resp. the final) residual error,    'nIter' is for the number of iterations needed to find the approximation.\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/#TensorDec.rne_n_tr_r","page":"Decomposition","title":"TensorDec.rne_n_tr_r","text":"rne_n_tr_r(P, A0, B0, Dict{String,Any}(\"maxIter\" => N,\"epsIter\" => ϵ))⤍ A, B, Info\n\nThis function gives a low symmetric rank approximation of a real valued symmetric tensor by applying an exact Riemannian Newton iteration with dog-leg trust region steps to the associate non-linear-least-squares problem. The optimization set is parameterized by weights and unit vectors. Let r be the approximation rank. The approximation is of the form of linear combination of r linear forms to the d-th power ∑wi*(vi^tx)^d, with i=1,...,r. This approximation is represented by a vector of r real numbers W=(wi) (weight vector), and a matrix of normalized columns V=[v1;...;v_r].\n\nInput:\n\nP: Homogeneous polynomial (associated to the symmetric tensor to approximate).\nA0: Initial weight vector of size equal to the approximation rank.\nB0: Initial matrix of row size equal to the dimension of P and column size equal to the  approximation rank.\n\nThe options are\n\nN: Maximal number of iterations (by default 500).\nϵ: The radius of the trust region (by default 1.e-3).\n\nOutput:\n\nA: Weight vector of size equal to the approximation rank.\nB: Matrix of row size equal to the dimension of P and column size equal to the\n\napproximation rank. The columns vectors of B are normalized.\n\nInfo: 'd0' (resp. 'd*') represents the initial (resp. the final) residual error,   'nIter' is for the number of iterations needed to find the approximation.\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/#TensorDec.rgn_v_tr","page":"Decomposition","title":"TensorDec.rgn_v_tr","text":"    rgn_v_tr(P, B0, Dict{String,Any}(\"maxIter\" => N,\"epsIter\" => ϵ))⤍ B, Info\n\nThis function gives a low symmetric rank approximation of a complex valued symmetric tensor by applying a Riemannian Gauss-Newton iteration with dog-leg trust region steps to the associate non-linear-least-squares problem. The optimization set is a cartesian product of Veronese manifolds. Let r be the approximation rank. The approximation is of the form of linear combination of r linear forms to the d-th power ∑(vi^tx)^d, with i=1,...,r. This approximation is represented by a matrix [v1;...;v_r].\n\nInput:\n\nP: Homogeneous polynomial (associated to the symmetric tensor to approximate).\nB0: Matrix of row size equal to the dimension of P and column size equal to the     approximation rank (initial point).\nN: Maximal number of iterations (by default 500).\nϵ: The radius of the trust region (by default 1.e-3).\n\nOutput:\n\nB: Matrix of row size equal to the dimension of P and column size equal to the approximation rank. This matrix contains the r vectors of the symmetric decomposition of the approximation.\nInfo: 'd0' (resp. 'd*') represents the initial (resp. the final) residual error,       'nIter' is for the number of iterations needed to find the approximation.\n\n\n\n\n\n","category":"function"},{"location":"code/3.decompose/","page":"Decomposition","title":"Decomposition","text":"TensorDec.weights","category":"page"},{"location":"code/3.decompose/#TensorDec.weights","page":"Decomposition","title":"TensorDec.weights","text":"weights(T, Xi::Matrix) -> Vector\n\nCompute the weight vector in the decomposition of the homogeneous polynomial T as a weighted sum of powers of the linear forms associated to the columns of Xi.\n\n\n\n\n\n","category":"function"},{"location":"expl/9.SphericalGaussianMixture/#Decomposition-of-a-mixture-of-spherical-Gaussians","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"","category":"section"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"The idea is to apply the Theorem 1 from (D. Hsu & S.M. Kakade, 2012) for r spherical Gaussian mixture  with differing covariances by using functions from the package TensorDec such that the symmetric low rank approximation functions to find the variances sigma_1sigma_r, the means mu_1mu_r and  the weights w_1w_r.  We denote by r the number of clusters obeying multivariate Gaussian distributions, by n the dimension or the number of features, and by N the number of vectors i.e., the number of the observations x_i in the data set S. Note that for the applicability of the theorem r should be smaller or equal to n.","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"# load the packages needed in this example\nusing TensorDec\nusing Distributions, GaussianMixtures, LinearAlgebra, Plots","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"n = 2 # number of features\nr = 2 # number of clusters\nN = 1000 # number of observations in the dataset\nw_real = [0.3, 0.7] # the cluster proportions, here we have two clusters one contains 30% from the observations and the other cluster contains 70% from the observations.\nMu_real = [[-5.0, -3.0], [-5.0, 4.0]] # the first (resp. the second) cluster obeying multivariate Gaussian distribution of mean [-5.0, -3.0] (resp. [-5.0, 4.0]). \nSigma_real = [0.4, 0.3]; # the covariance matrix in the first (resp. the second) Gaussian distribution is 0.4*I (resp. 0.3*I) where I is the identity matrix.","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"# Randomaly sample a dataset of N points obeying spherical Gaussian mixture according to the parameters w_real, Mu_real and Sigma_real.\nNrm = [MvNormal([Mu_real[i]...,i],Diagonal([ones(n)*Sigma_real[i]...,0]))  for i in 1:r]\nMix_of_Gaussians = MixtureModel(Nrm[1:r],w_real)\nS_label = rand(Mix_of_Gaussians, N)","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"3×1000 Array{Float64,2}:\n -6.93469  -5.03918  -5.26152  -5.83157  …  -5.45367  -4.80835  -4.39562\n -3.28932   3.79391   3.29996   4.65434      4.15295  -2.44732  -3.83481\n  1.0       2.0       2.0       2.0          2.0       1.0       1.0","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"We can notice that we obtain with this code a matrix S_label where the number of columns is the number of the observations equal to N=1000, the last row in this matrix contains the labels of the clusters, for example the first point (-6.93469, -3.28932) is in the cluster 1 the next point is in the cluster 2...etc, this helps us to separate the two clusters using different colors in the plot (see the plot at the end of this notebbok). ","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"# here we take the dataset without the clusters to apply the method of moments.\nS = S_label[1:n,:]","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"2×1000 Array{Float64,2}:\n -6.93469  -5.03918  -5.26152  -5.83157  …  -5.45367  -4.80835  -4.39562\n -3.28932   3.79391   3.29996   4.65434      4.15295  -2.44732  -3.83481","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"# the function moments_var_diff applies the method of moments by taking as arguments the dataset S and the number of clusters r and\n# returns the estimated weights vector 'w_pred', the means in columns in a matrix 'Mu_pred', and the variances in a vector 'Sigma_pred'.    \nw_pred, Mu_pred, Sigma_pred = moment_var_diff(S,r)","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"([0.30746190732797457, 0.6925380926720255], [-4.9867727722153905 -4.997716895030157; -2.996896461673346 3.9751432109706357], [0.38691174790834876, 0.30802777553042104])","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"# put Mu_pred in the same form as Mu_real.\nMu_pred = [Mu_pred[:,i] for i in 1:r]","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"2-element Array{Array{Float64,1},1}:\n [-4.9867727722153905, -2.996896461673346]\n [-4.997716895030157, 3.9751432109706357]","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"Let us look at the real parameters and the estimated parameters obtained by <font color='red'>momentvardiff</font>. ","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"print(\"w_real: \", w_real, \"\\n\")\nprint(\"w_pred: \", w_pred)\n","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"w_real: [0.3, 0.7]\nw_pred: [0.30746190732797457, 0.6925380926720255]","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"print(\"Mu_real: \", Mu_real, \"\\n\")\nprint(\"Mu_pred: \", Mu_pred)","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"Mu_real: [[-5.0, -3.0], [-5.0, 4.0]]\nMu_pred: [[-4.9867727722153905, -2.996896461673346], [-4.997716895030157, 3.9751432109706357]]","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"print(\"Sigma_real: \", Sigma_real, \"\\n\")\nprint(\"Sigma_pred: \", Sigma_pred)","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"Sigma_real: [0.4, 0.3]\nSigma_pred: [0.38691174790834876, 0.30802777553042104]","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"# for the scatter plot we need the matrix form of Mu_real and Mu_pred. \nMu_real = [-5.0 -5.0\n           -3.0  4.0]\nMu_pred = [-4.9867727722153905 -4.997716895030157 \n           -2.996896461673346 3.9751432109706357]","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"2×2 Array{Float64,2}:\n -4.98677  -4.99772\n -2.9969    3.97514","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"fig = plot(S[1,:],S[2,:], zcolor = S_label[end,:]/r, m = ColorGradient([:pink, :lightblue]), seriestype = :scatter, legend=false, msw = 0, label =\"\", fmt=:png)\nfig = plot!(Mu_real[1,:], Mu_real[2,:], seriestype = :scatter, m = (:yellow, [:circle], 7),label = \"Real_means\", fmt=:png) \nfig = scatter!(Mu_pred[1,:], Mu_pred[2,:], m = (:red, [:star7], 5), label = \"Estimated_means\", legend = true)","category":"page"},{"location":"expl/9.SphericalGaussianMixture/","page":"Decomposition of a mixture of spherical Gaussians","title":"Decomposition of a mixture of spherical Gaussians","text":"(Image: png)","category":"page"},{"location":"code/2.polynomials/#Polynomials","page":"Polynomials","title":"Polynomials","text":"","category":"section"},{"location":"code/2.polynomials/","page":"Polynomials","title":"Polynomials","text":"Pages = [\"2.polynomials.md\"]","category":"page"},{"location":"code/2.polynomials/","page":"Polynomials","title":"Polynomials","text":"TensorDec.hpol\nTensorDec.ahp","category":"page"},{"location":"code/2.polynomials/#TensorDec.hpol","page":"Polynomials","title":"TensorDec.hpol","text":"hpol(W,A,X,d) ⤍ Homogeneous polynomial\n\nThis function gives the homogeneous polynomial associated to the symmetric decomposition W,A.\n\n```\n\n\n\n\n\n","category":"function"},{"location":"code/2.polynomials/#TensorDec.ahp","page":"Polynomials","title":"TensorDec.ahp","text":"ahp(T::symmetric Tensor, X=@polyvar x1...xn)-> 'P' Associated homogeneous polynomial\n\nThe associated homogeneous polynomials of degree d in n variables of a symmetric tensor of order d and dimension n.\n\nExample\n\njulia> n=2\n2\n\njulia> d=3\n3\n\njulia> T\n2×2×2 Array{Float64,3}:\n[:, :, 1] =\n -3.0  -1.5\n -1.5   0.0\n\n[:, :, 2] =\n -1.5  0.0\n  0.0  1.5\n\njulia> X=@polyvar x1 x2\n2-element Array{PolyVar{true},1}:\n x1\n x2\n\n julia> P=ahp(T,X)\n (-3.0 + 0.0im)x1³ + (-4.5 + 0.0im)x1²x2 + (1.5 + 0.0im)x2³\n\n\n\n\n\n","category":"function"},{"location":"code/2.polynomials/","page":"Polynomials","title":"Polynomials","text":"perp","category":"page"},{"location":"code/2.polynomials/#TensorDec.perp","page":"Polynomials","title":"TensorDec.perp","text":"Compute the kernel of the Hankel matrix in degree d of the symmetric tensor F.\n\n\n\n\n\n","category":"function"},{"location":"code/2.polynomials/","page":"Polynomials","title":"Polynomials","text":"hilbert","category":"page"},{"location":"code/2.polynomials/#TensorDec.hilbert","page":"Polynomials","title":"TensorDec.hilbert","text":"Sequence of dimension of S(F^) or of the kernels of the Hankel matrix in degree i for i in 1:maxdegree(F).\n\n\n\n\n\n","category":"function"},{"location":"expl/8.2.Sym_rank_approx/#Low-rank-approximation-of-symmetric-tensors","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"","category":"section"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"Let us take a random symmetric tensor normally distributed with complex coefficients of order 4 and dimension 3 (the generic symmetric rank is 5), and let us compute by the Riemannian Newton algorithm \"rnentr\" and the Riemannian Gauss–Newton algorithm \"rgnvtr\" initialized by a random initial point obeying normal distribution an approximated rank-3 symmetric tensor.   ","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"using TensorDec\nusing DynamicPolynomials\nusing LinearAlgebra # Take a random symmetric tensor\nusing Tensors\nn = 3; d = 4; r = 3\nT = randn(SymmetricTensor{d, n})+randn(SymmetricTensor{d, n})*im\nT = convert(Array,T)\n# show the first 3 arrays of T\nT[:,:,:,1]","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"3×3×3 Array{ComplexF64, 3}:\n[:, :, 1] =\n -0.907877-0.704053im   1.63111+1.9166im    0.707683-1.10415im\n   1.63111+1.9166im    0.356316-0.864636im  0.266712-1.17115im\n  0.707683-1.10415im   0.266712-1.17115im   -1.00707+1.11311im\n\n[:, :, 2] =\n     0.888359+1.18551im   -0.000287941+0.994591im   0.063549+0.920767im\n -0.000287941+0.994591im       0.44311+1.95581im   -0.571079+1.21967im\n     0.063549+0.920767im     -0.571079+1.21967im    0.478346-1.00253im\n\n[:, :, 3] =\n 0.474927+0.225965im   0.345004+0.096659im  0.378529+0.621547im\n 0.345004+0.096659im  -0.454708-0.323135im  0.326064-0.518541im\n 0.378529+0.621547im   0.326064-0.518541im  0.988977+1.29563im","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"# Take the associate homogeneous polynomial P to T by applying the function ahp (for associate homogeneous polynomial)\nX = (@polyvar x[1:n])[1]\nP = ahp(T, X);","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"# Take an initial point \nw = ones(r) + fill(0.0+0.0im,r);\nV = randn(ComplexF64,n,r);","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"Applying Riemannian Newton Exact (rne_n_tr) iterations:","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"w_end, V_end, InfoRNE = approximate(P, w, V; iter = :RNE)","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"(ComplexF64[5.05399865445625 + 0.0im, 2.3774909931035793 + 0.0im, 5.564701632935593 + 0.0im], ComplexF64[-0.25708654259621544 - 0.20934184778311407im 0.26528717387960404 + 0.16372231300068174im 0.13244665877211262 + 0.2861924486462175im; 0.23097764100261176 - 0.1401358654004084im 0.6261850699359142 - 0.48265493517648883im 0.06264828073916878 + 0.4549788626666184im; 0.655360519402606 + 0.6225723721595502im 0.008275536105741 - 0.5269589232966605im -0.8262225174137973 + 0.0835316950828236im], Dict{String, Real}(\"d*\" => 7.220881621837435, \"d0\" => 40.4276760623482, \"nIter\" => 16, \"epsIter\" => 0.001, \"maxIter\" => 500))","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The reported error is the apolar norm between P and the approximated polynomial. ","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The initial error is:","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"InfoRNE[\"d0\"]","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"40.4276760623482","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The final error is:","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"InfoRNE[\"d*\"]","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"7.220881621837435","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The number of iterations is:","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"InfoRNE[\"nIter\"]","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"16","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"Applying Riemannian Gauss Newton (rgn_v_tr) iterations, one get","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"w_end, V_end, InfoRGN = approximate(P, w, V; iter = :RGN)","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"(ComplexF64[1.0 + 0.0im, 1.0 + 0.0im, 1.0 + 0.0im], ComplexF64[-0.5659979695826164 + 0.10726026844883924im 0.5537406971164952 - 0.34006502788737575im -0.6679966971954102 - 0.05400208838285853im; -0.027432255695650554 - 0.8758998721814316im -0.7730184477273698 - 0.14900174020833434im -0.23146942680034654 + 0.243865447597017im; -0.6287959782796702 + 0.7614820898258986im -0.6721479704250028 - 0.8450340224335604im -0.044370920631584404 - 1.2234092058320365im], Dict{String, Real}(\"d*\" => 4.379474567662476, \"d0\" => 40.4276760623482, \"nIter\" => 218, \"epsIter\" => 0.001, \"maxIter\" => 500))","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The reported error is the apolar norm between P and the approximated polynomial.","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The initial error is:","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"InfoRGN[\"d0\"]","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"40.4276760623482","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The final error is:","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"InfoRGN[\"d*\"]","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"4.379474567662476","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"The number of iterations is:","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"InfoRGN[\"nIter\"]","category":"page"},{"location":"expl/8.2.Sym_rank_approx/","page":"Low rank approximation of symmetric tensors","title":"Low rank approximation of symmetric tensors","text":"218","category":"page"},{"location":"expl/2.MultilinearTensor/#Multilinear-tensors","page":"Multilinear tensors","title":"Multilinear tensors","text":"","category":"section"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"using TensorDec","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"We consider a multi-linear tensor of size 3 x 5 x 4, which is sum of r=4 tensor products of the random column vectors of the matrices A0, B0, C0with weights w0:","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"r=4\nw0 = rand(r)\nA0 = rand(3,r)\nB0 = rand(5,r)\nC0 = rand(4,r)\n\nT0 = tensor(w0, A0, B0, C0)","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"3×5×4 Array{Float64, 3}:\n[:, :, 1] =\n 0.316184  0.345023   0.382037  0.36165   0.486526\n 0.404335  0.276629   0.434605  0.344533  0.509244\n 0.111832  0.0641309  0.111185  0.103334  0.11392\n\n[:, :, 2] =\n 0.353912  0.447882  0.428276  0.478536  0.565683\n 0.491082  0.387773  0.529839  0.517911  0.582768\n 0.175713  0.117616  0.188383  0.200218  0.146661\n\n[:, :, 3] =\n 0.234157  0.189894   0.277909  0.200739  0.326495\n 0.333178  0.184865   0.373708  0.241155  0.376656\n 0.104873  0.0597654  0.117054  0.100222  0.088638\n\n[:, :, 4] =\n 0.372136  0.0808872  0.301894   0.187236   0.398308\n 0.499487  0.093278   0.399356   0.240435   0.524856\n 0.126637  0.0208347  0.0864272  0.0717313  0.127397","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"We compute its decomposition:","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"w, A, B, C = decompose(T0);","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"We obtain a decomposition of rank 4 with weights:","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"w","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"4-element Vector{Float64}:\n 0.33792668673343457\n 0.7408084924294192\n 0.9605854249810668\n 1.0267280992544108","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"The r=4 vectors of norm 1 of the first components of the decomposition are the columns of the matrix A:  ","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"A","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"3×4 Matrix{Float64}:\n 0.0808627  0.576234  0.590579  0.831589\n 0.744569   0.778708  0.794381  0.548351\n 0.66263    0.248132  0.142043  0.0881477","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"The r=4 vectors  of norm 1 of the second components are the columns of the matrix B: ","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"B","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"5×4 Matrix{Float64}:\n 0.414404  0.624532   0.503332   -0.136551\n 0.334042  0.0598829  0.108848   -0.615309\n 0.571347  0.233124   0.623258   -0.335895\n 0.607836  0.469743   0.0629459  -0.52911\n 0.144163  0.575646   0.585147   -0.458221","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"The r=4 vectors of norm 1 of the third components are the columns of the matrix C:","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"C","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"4×4 adjoint(::Matrix{Float64}) with eltype Float64:\n 0.273397   0.39815   0.489947  -0.575025\n 0.84564    0.521266  0.407014  -0.764628\n 0.458126   0.232774  0.467259  -0.287248\n 0.0163813  0.718035  0.613156  -0.0466739","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"It corresponds to the tensor sum_i=1^r w_i  Ai otimes Bi otimes Ci for i in 1r:","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"T = tensor(w, A, B, C)","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"3×5×4 Array{Float64, 3}:\n[:, :, 1] =\n 0.316184  0.345023   0.382037  0.36165   0.486526\n 0.404335  0.276629   0.434605  0.344533  0.509244\n 0.111832  0.0641309  0.111185  0.103334  0.11392\n\n[:, :, 2] =\n 0.353912  0.447882  0.428276  0.478536  0.565683\n 0.491082  0.387773  0.529839  0.517911  0.582768\n 0.175713  0.117616  0.188383  0.200218  0.146661\n\n[:, :, 3] =\n 0.234157  0.189894   0.277909  0.200739  0.326495\n 0.333178  0.184865   0.373708  0.241155  0.376656\n 0.104873  0.0597654  0.117054  0.100222  0.088638\n\n[:, :, 4] =\n 0.372136  0.0808872  0.301894   0.187236   0.398308\n 0.499487  0.093278   0.399356   0.240435   0.524856\n 0.126637  0.0208347  0.0864272  0.0717313  0.127397","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"We compute the L^2 norm of the difference between T and T_0:","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"using LinearAlgebra\nnorm(T-T0)","category":"page"},{"location":"expl/2.MultilinearTensor/","page":"Multilinear tensors","title":"Multilinear tensors","text":"5.414241769776905e-15","category":"page"},{"location":"expl/1.SymmetricTensor/#Symmetric-tensors","page":"Symmetric tensors","title":"Symmetric tensors","text":"","category":"section"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"using TensorDec","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"We consider symmetric tensors or equivalently homogeneous polynomials, in the following variables:","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"using TensorDec, DynamicPolynomials\nX = @polyvar x0 x1 x2;","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"A symmetric tensor of order d=4 and of rank 3.","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"d=4; F = (x0+x1+0.75x2)^d + 1.5*(x0-x1)^d -2.0*(x0-x2)^d","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"0.5x0^{4} - 2.0x0^{3}x1 + 11.0x0^{3}x2 + 15.0x0^{2}x1^{2} + 9.0x0^{2}x1x2 - 8.625x0^{2}x2^{2} - 2.0x0x1^{3} + 9.0x0x1^{2}x2 + 6.75x0x1x2^{2} + 9.6875x0x2^{3} + 2.5x1^{4} + 3.0x1^{3}x2 + 3.375x1^{2}x2^{2} + 1.6875x1x2^{3} - 1.68359375x2^{4}","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"The graph of the homogeneous polynomial (x_0+x_1+075x_2)^4 + 15(x_0-x_1)^4 -2(x_0-x_2)^4 in polar coordinates on the sphere looks like this:","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"(Image: tensor)","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"We associate to t, the following (truncated) series in the dual variables, after substituting x_0 by 1:","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"Computing its decomposition","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"w, Xi = decompose(F);","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"yields the weights w","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"w","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"3-element Array{Float64,1}:\n  1.4999999999999996\n -1.9999999999999987\n  0.9999999999999999","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"and the corresponding points Xi, which are the coefficient vectors of x_0 x_1 x_2 in the linear forms of the decomposition of the tensor F. They are normalized to have norm 1:","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"Xi","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"3×3 Array{Float64,2}:\n  1.0           1.0          1.0 \n -1.0           4.15916e-16  1.0 \n  1.03483e-16  -1.0          0.75","category":"page"},{"location":"expl/1.SymmetricTensor/","page":"Symmetric tensors","title":"Symmetric tensors","text":"","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/#Best-rank-one-approximation-and-optimization-on-the-sphere","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"","category":"section"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"using TensorDec\nusing DynamicPolynomials\n\n# Define the parameters\nX = @polyvar x1 x2 x3\n\n# P is a homogeneous polynomial of degree 4 in 3 variables\nP = (x1+x2+0.75*x3)^4+1.5*(x1-x2)^4-2*(x1-x3)^4","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"$","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"0.5x1^{4} - 2.0x1^{3}x2 + 11.0x1^{3}x3 + 15.0x1^{2}x2^{2} + 9.0x1^{2}x2x3 - 8.625x1^{2}x3^{2} - 2.0x1x2^{3} + 9.0x1x2^{2}x3 + 6.75x1x2x3^{2} + 9.6875x1x3^{3} + 2.5x2^{4} + 3.0x2^{3}x3 + 3.375x2^{2}x3^{2} + 1.6875x2x3^{3} - 1.68359375x3^{4} $","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"The graph of P in polar coordinates on the sphere looks like this:","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"(Image: title)","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"Let us compute a rank-1 approximation of P. We will compute an initial point by the method SMD, the Julia function that corresponds to this method in the package TensorDec is called \"decompose\", then we will use the Riemannian Newton algorithm with trust region scheme for the real case, the corresponding Julia function in the package TensorDec is called \"rnentr_r\".","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"# Compute an initial point\nw1, V1 = decompose(P,1)","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"([6.545493350772277], [-0.6072039195594636; -0.6330986129014177; -0.4800932684530426;;], Dict{String, Any}(\"diagonalization\" => Dict{String, Any}(\"case\" => \"1x1\")))","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"Let us refine this point by using a few number of iterations of rnentr_r, for example 5 iterations.","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"w_end, V_end, Info = approximate(P, w1, V1; iter= :RNE)","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"([6.565249939277385], [-0.6236914922916466; -0.624802695988649; -0.4697132247747928;;], Dict{String, Real}(\"d*\" => 9.695336978192456, \"d0\" => 9.699451819228086, \"nIter\" => 4, \"epsIter\" => 0.001, \"maxIter\" => 500))","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"The weight in absolute value given by rnentr_r initialized by decompose for rank-1 symmetric tensor approximation is: 7.701576525649196.","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"The unit vector given by rnentr_r initialized by decompose for rank-1 symmetric tensor approximation is: [0.68061769889553; 0.04831896554028091; -0.7310436550024019].","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/#Comparing-with-polynomial-optimization","page":"Best rank one approximation and optimization on the sphere","title":"Comparing with polynomial optimization","text":"","category":"section"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"Let us use now polynomial optimization to get the spectral norm of P. We use the package MomentToolsand the SDP solver CSDP. To compute this specttral norm, we  minimize and maximize P on the unit sphere. The maximum evaluation of P in absolute value on the unit sphere (and that is why we have to use both maximize and minimize functions) gives the spectral norm of P and equivalently a best rank-1 approximation of the symmetric tensor associated to P.","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"using MomentTools\nusing CSDP, JuMP\n# The function \"Optimizer\" is a global optimization solver based on positive semi-definite programming\noptimizer = CSDP.Optimizer\n#using LinearAlgebra\n\nv1, M1 = minimize(P, [x1^2+x2^2+x3^2-1], [], X, 8, optimizer);\nv2, M2 = maximize(P, [x1^2+x2^2+x3^2-1], [], X, 8, optimizer);","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"CSDP 6.2.0\nIter:  0 Ap: 0.00e+00 Pobj:  0.0000000e+00 Ad: 0.00e+00 Dobj:  0.0000000e+00 \nIter:  1 Ap: 6.27e-01 Pobj: -9.1377312e+00 Ad: 6.65e-01 Dobj:  6.5822601e+00 \nIter:  2 Ap: 1.00e+00 Pobj: -8.9378911e+01 Ad: 5.42e-01 Dobj:  6.7430765e+00 \nIter:  3 Ap: 1.00e+00 Pobj: -7.8427861e+01 Ad: 8.83e-01 Dobj:  1.1629773e+00 \nIter:  4 Ap: 1.00e+00 Pobj: -4.7706795e+01 Ad: 8.97e-01 Dobj:  3.8603631e-01 \nIter:  5 Ap: 1.00e+00 Pobj: -1.8751219e+01 Ad: 7.72e-01 Dobj:  5.1044080e-02 \nIter:  6 Ap: 7.86e-01 Pobj: -8.9568745e+00 Ad: 9.24e-01 Dobj: -1.6229630e+00 \nIter:  7 Ap: 9.83e-01 Pobj: -8.6192083e+00 Ad: 7.44e-01 Dobj: -6.4997642e+00 \nIter:  8 Ap: 7.68e-01 Pobj: -7.8344478e+00 Ad: 7.62e-01 Dobj: -7.2868769e+00 \nIter:  9 Ap: 9.65e-01 Pobj: -7.7124187e+00 Ad: 8.41e-01 Dobj: -7.6028422e+00 \nIter: 10 Ap: 9.33e-01 Pobj: -7.7024600e+00 Ad: 9.51e-01 Dobj: -7.6931385e+00 \nIter: 11 Ap: 9.37e-01 Pobj: -7.7016436e+00 Ad: 9.79e-01 Dobj: -7.7012173e+00 \nIter: 12 Ap: 9.65e-01 Pobj: -7.7015833e+00 Ad: 1.00e+00 Dobj: -7.7015626e+00 \nIter: 13 Ap: 9.39e-01 Pobj: -7.7015799e+00 Ad: 1.00e+00 Dobj: -7.7015768e+00 \nIter: 14 Ap: 1.00e+00 Pobj: -7.7015796e+00 Ad: 1.00e+00 Dobj: -7.7015805e+00 \nIter: 15 Ap: 1.00e+00 Pobj: -7.7015795e+00 Ad: 1.00e+00 Dobj: -7.7015804e+00 \nIter: 16 Ap: 1.00e+00 Pobj: -7.7015795e+00 Ad: 1.00e+00 Dobj: -7.7015796e+00 \nIter: 17 Ap: 1.00e+00 Pobj: -7.7015795e+00 Ad: 1.00e+00 Dobj: -7.7015795e+00 \nIter: 18 Ap: 9.60e-01 Pobj: -7.7015795e+00 Ad: 9.55e-01 Dobj: -7.7015795e+00 \nSuccess: SDP solved\nPrimal objective value: -7.7015795e+00 \nDual objective value: -7.7015795e+00 \nRelative primal infeasibility: 4.06e-14 \nRelative dual infeasibility: 1.75e-10 \nReal Relative Gap: -2.67e-11 \nXZ Relative Gap: 1.00e-09 \nDIMACS error measures: 7.27e-14 0.00e+00 2.69e-10 0.00e+00 -2.67e-11 1.00e-09\nCSDP 6.2.0\nIter:  0 Ap: 0.00e+00 Pobj:  0.0000000e+00 Ad: 0.00e+00 Dobj:  0.0000000e+00 \nIter:  1 Ap: 6.08e-01 Pobj: -8.9542595e+00 Ad: 6.64e-01 Dobj: -2.1488584e+01 \nIter:  2 Ap: 1.00e+00 Pobj: -9.4142852e+01 Ad: 5.33e-01 Dobj: -1.5637445e+01 \nIter:  3 Ap: 1.00e+00 Pobj: -8.1334623e+01 Ad: 8.84e-01 Dobj: -2.2425292e+00 \nIter:  4 Ap: 1.00e+00 Pobj: -5.0436110e+01 Ad: 9.00e-01 Dobj: -1.2447457e+00 \nIter:  5 Ap: 1.00e+00 Pobj: -2.0096267e+01 Ad: 7.90e-01 Dobj: -1.4739780e+00 \nIter:  6 Ap: 8.12e-01 Pobj: -9.3624346e+00 Ad: 8.98e-01 Dobj: -2.4116592e+00 \nIter:  7 Ap: 6.62e-01 Pobj: -6.7261120e+00 Ad: 8.43e-01 Dobj: -4.2835821e+00 \nIter:  8 Ap: 1.00e+00 Pobj: -7.2082331e+00 Ad: 5.32e-01 Dobj: -5.8373968e+00 \nIter:  9 Ap: 9.20e-01 Pobj: -6.6141990e+00 Ad: 9.19e-01 Dobj: -6.4775431e+00 \nIter: 10 Ap: 9.53e-01 Pobj: -6.5676395e+00 Ad: 9.60e-01 Dobj: -6.5604450e+00 \nIter: 11 Ap: 9.57e-01 Pobj: -6.5653593e+00 Ad: 9.82e-01 Dobj: -6.5650429e+00 \nIter: 12 Ap: 9.67e-01 Pobj: -6.5652544e+00 Ad: 9.20e-01 Dobj: -6.5652369e+00 \nIter: 13 Ap: 8.76e-01 Pobj: -6.5652507e+00 Ad: 9.85e-01 Dobj: -6.5652503e+00 \nIter: 14 Ap: 5.02e-01 Pobj: -6.5652503e+00 Ad: 1.00e+00 Dobj: -6.5652504e+00 \nIter: 15 Ap: 1.00e+00 Pobj: -6.5652500e+00 Ad: 1.00e+00 Dobj: -6.5652501e+00 \nIter: 16 Ap: 1.00e+00 Pobj: -6.5652500e+00 Ad: 1.00e+00 Dobj: -6.5652501e+00 \nIter: 17 Ap: 1.00e+00 Pobj: -6.5652500e+00 Ad: 1.00e+00 Dobj: -6.5652500e+00 \nIter: 18 Ap: 9.60e-01 Pobj: -6.5652500e+00 Ad: 9.44e-01 Dobj: -6.5652500e+00 \nSuccess: SDP solved\nPrimal objective value: -6.5652500e+00 \nDual objective value: -6.5652500e+00 \nRelative primal infeasibility: 6.88e-15 \nRelative dual infeasibility: 1.23e-09 \nReal Relative Gap: -2.17e-10 \nXZ Relative Gap: 9.80e-09 \nDIMACS error measures: 1.23e-14 0.00e+00 1.88e-09 0.00e+00 -2.17e-10 9.80e-09","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"The minimum evaluation of P on the unit sphere is: -7.701579459519532.","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"The maximum evaluation of P on the unit sphere is: 6.565249952183416.","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"Thus, the maximum weight in absolute value, which is the spectral norm of P, is: 7.701579459519532.","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"The unit vectors that give this value are: [0.6805571886747267, 0.048429787707634814, -0.7310926539221407] and [-0.6805571886747267, -0.048429787707634814, 0.7310926539221407].","category":"page"},{"location":"expl/8.1.Sym_rank_one_approx/","page":"Best rank one approximation and optimization on the sphere","title":"Best rank one approximation and optimization on the sphere","text":"We verify that the second vector and the second weight correspond to the best rank-1 approximation w_end(v_end^tX)^4 of P, given by \"rnentr_r\" iterations.","category":"page"},{"location":"code/1.series/#Series","page":"Series","title":"Series","text":"","category":"section"},{"location":"code/1.series/","page":"Series","title":"Series","text":"Pages = [\"1.series.md\"]","category":"page"},{"location":"code/1.series/","page":"Series","title":"Series","text":"dual","category":"page"},{"location":"code/1.series/#MultivariateSeries.dual","page":"Series","title":"MultivariateSeries.dual","text":"dual(p::Polynomial, d:: Int64) -> Series{T}\n\nCompute the series associated to the tensor p of degree d. T is the type of the coefficients of the polynomial p.\n\n\n\n\n\n","category":"function"},{"location":"code/1.series/","page":"Series","title":"Series","text":"hankel ","category":"page"},{"location":"code/1.series/#MultivariateSeries.hankel","page":"Series","title":"MultivariateSeries.hankel","text":"Compute the Hankel matrix (a.k.a. Catalecticant matrix) in degree d of the symmetric tensor F.\n\n\n\n\n\n","category":"function"},{"location":"expl/0.Decomposition/#Decomposition-algorithm","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"","category":"section"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"using TensorDec, DynamicPolynomials\nusing LinearAlgebra\nX = @polyvar x1 x2 x3","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3-element Array{DynamicPolynomials.PolyVar{true},1}:\n x1\n x2\n x3","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"We want to find a sparse representation of the following series known up to degree 3:","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"sigma = dual(6.0 + 4.0*x1 + 15.0*x2 + 6.0*x3 + 6.0*x1^2 + 20.0*x1*x2 + 4.0*x1*x3 + 43.0*x2^2 + 15.0*x2*x3 + 6.0*x3^2 - 26.0*x1^3 + 30.0*x1^2*x2 + 6.0*x1^2*x3 + 72.0*x1*x2^2 + 20.0*x1*x2*x3 + 4.0*x1*x3^2 + 129.0*x2^3 + 43.0*x2^2*x3 + 15.0*x2*x3^2 + 6.0*x3^3)","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"4.0dx1*dx3 + 15.0dx2 + 6.0dx3 + 20.0dx1*dx2 + 6.0dx3^3 + 43.0dx2^2dx3 - 26.0dx1^3 + 129.0dx2^3 + 30.0dx1^2dx2 + 15.0dx2*dx3 + 20.0dx1*dx2*dx3 + 6.0dx1^2 + 6.0dx3^2 + 4.0dx1 + 43.0dx2^2 + 6.0dx1^2dx3 + 4.0dx1*dx3^2 + 72.0dx1*dx2^2 + 15.0dx2*dx3^2 + 6.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"L1 = monoms(X,1)\nL2 = monoms(X,2)","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"10-element Array{DynamicPolynomials.Monomial{true},1}:\n 1   \n x1  \n x2  \n x3  \n x1² \n x1x2\n x1x3\n x2² \n x2x3\n x3²","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"H = hankel(sigma,L1,L2)","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"4×10 Array{Float64,2}:\n  6.0   4.0  15.0   6.0    6.0  20.0   4.0   43.0  15.0   6.0\n  4.0   6.0  20.0   4.0  -26.0  30.0   6.0   72.0  20.0   4.0\n 15.0  20.0  43.0  15.0   30.0  72.0  20.0  129.0  43.0  15.0\n  6.0   4.0  15.0   6.0    6.0  20.0   4.0   43.0  15.0   6.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"The rank of H_sigma will give us an idea on the dimension of mathcalA_sigma.","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"rank(H)","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"We check that 1 x_1 x_2 is a basis of mathcalA_sigma: ","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"B0 = L1[1:3]","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3-element Array{DynamicPolynomials.Monomial{true},1}:\n 1 \n x1\n x2","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"H0 = hankel(sigma, B0, B0)","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n  6.0   4.0  15.0\n  4.0   6.0  20.0\n 15.0  20.0  43.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"rank(H0)","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"Let us compute the shifted (truncated) Hankel operators.","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"H1 = hankel(sigma, B0, B0*x1)\nH2 = hankel(sigma, B0, B0*x2)\nH3 = hankel(sigma, B0, B0*x3);\nH  = [H1,H2,H3]\nH[1]","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n  4.0    6.0  20.0\n  6.0  -26.0  30.0\n 20.0   30.0  72.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"M = [ H0^(-1)*H[i] for i in 1:3 ]\nM[1]","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n  1.11022e-16   9.14286  -0.571429\n  1.0           3.85714   1.57143 \n -1.11022e-16  -4.28571   1.14286","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"The eigenvalues and eigenvectors of M_x_1 are","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"We deduce the operators of multiplication by the variables in the basis B_0:","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"v, E = eigen(M[1])","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"Eigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}\neigenvalues:\n3-element Array{Float64,1}:\n -0.9999999999999991\n  4.000000000000002 \n  2.000000000000002 \neigenvectors:\n3×3 Array{Float64,2}:\n  0.963087  -0.811107  -0.762001\n -0.120386  -0.324443  -0.127   \n -0.240772   0.486664   0.635001","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"The matrices M_x_i are diagonal in this basis:","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"D = [E^(-1)*M[i]*E for i in 1:3]\nD[1]","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n -1.0          -6.99441e-15  -3.66374e-15\n  4.21885e-15   4.0          -4.44089e-15\n -4.66294e-15  -3.9968e-15    2.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"D[2]","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n  1.0          -4.44089e-16  -1.44329e-15\n  8.88178e-16   2.0           2.66454e-15\n -3.55271e-15   2.66454e-15   3.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"D[3]","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n  1.0           3.33067e-16  1.11022e-16\n -9.4369e-16    1.0          6.66134e-16\n  5.55112e-16  -6.66134e-16  1.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"Looking at the corresponding terms on the diagonal, we get the coordinates of the points Xi:","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"Xi = [ D[i][j,j] for i in 1:3, j in 1:3]","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n -1.0  4.0  2.0\n  1.0  2.0  3.0\n  1.0  1.0  1.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"We normalize the eigenvectors by v_i over v_i(xi_i) and get the interpolation polynomials at the points xi_i:","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"Dg = E'*vcat(fill(1.,1,3), Xi[1:2,:])\nE = E*Dg^(-1)\nU = E'*B0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3-element Array{DynamicPolynomials.Polynomial{true,Float64},1}:\n -0.14285714285714324x1 - 0.2857142857142862x2 + 1.142857142857143 \n 0.28571428571428614x1 - 0.4285714285714279x2 + 0.7142857142857121 \n -0.14285714285714332x1 + 0.7142857142857134x2 - 0.8571428571428543","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"We deduce the weights w_i=sigma(u_i):","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"w = hankel(sigma, U, [L1[1]])","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×1 Array{Float64,2}:\n  1.999999999999992 \n -1.0000000000000018\n  5.000000000000002","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"Using the command decompose, we can get directly the same decomposition: ","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"w, Xi = decompose(sigma)","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"([-1.0, 5.0, 2.0], [4.0 2.0 -1.0; 2.0 3.0 1.0; 1.0 1.0 1.0])","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"Xi","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3×3 Array{Float64,2}:\n 4.0  2.0  -1.0\n 2.0  3.0   1.0\n 1.0  1.0   1.0","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"w","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"3-element Array{Float64,1}:\n -1.0000000000000129\n  5.000000000000011 \n  1.9999999999999998","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"The series decomposes as 2 mathfrake_(-111) + 5 mathfrake_(231) - mathfrake_(421).","category":"page"},{"location":"expl/0.Decomposition/","page":"Decomposition algorithm","title":"Decomposition algorithm","text":"","category":"page"},{"location":"code/0.tensors/#Tensors","page":"Tensors","title":"Tensors","text":"","category":"section"},{"location":"code/0.tensors/","page":"Tensors","title":"Tensors","text":"Pages = [\"O.tensors.md\"]","category":"page"},{"location":"code/0.tensors/","page":"Tensors","title":"Tensors","text":"tensor","category":"page"},{"location":"code/0.tensors/#TensorDec.tensor","page":"Tensors","title":"TensorDec.tensor","text":"tensor(w, Xi, V, d) -> Polynomial{true,T} \n\nCompute  wᵢ (ξ_i1 V₁ +  + ξ_in Vₙ)ᵈ where \n\nXi is a column-wise matrix of r points, \nV  is a vector of variables,\nd  is a degree.\n\nExample\n\nusing TensorDec, DynamicPolynomials\nX = @polyvar x0 x1 x2\nw = rand(5)\nXi = rand(3,5)\ntensor(w,Xi,X,4)\n\n\n\n\n\ntensor(w, Xi, V, d) -> MultivariatePolynomial\n\nCompute  wᵢ Π_j(ξ_ij1 Vj1 +  + ξ_ijn_j Vjn_j)^dj where \n\nXi is a vector of matrices of points, \nV  is a vector of vectors of variables,\nd  is a vector of degrees.\n\nExample\n\nusing TensorDec, DynamicPolynomials\nX = @polyvar x0 x1 x2\nY = @polyvar y0 y1\nw = rand(5)\nXi0 = rand(3,5)\nXi1 = rand(2,5)\ntensor(w,[Xi0,Xi1],[X,Y],[4,2])\n\n\n\n\n\ntensor(H, L1, L2) -> MultivariatePolynomial\n\nCompute the symmetric tensor or homogeneous polynomial which Hankel matrix in the bases L1, L2 is H.\n\n\n\n\n\ntensor(s, X, d) -> MultivariatePolynomial\n\nCompute the symmetric tensor or homogeneous polynomial in the variables X corresponding to the series s. The coefficients s_alpha are multiplied by binomial(dalpha). The monomials are homogenised in degree d with respect to the last variable of X0.\n\n\n\n\n\ntensor(A, B, C) -> Array{K,3}\n\nCompute the trilinear tensor T=(_l=1^length(w) Ail*Bjl*Ckl)_ijk. \n\n\n\n\n\ntensor(w, A, B, C) -> Array{K,3}\n\nCompute the trilinear tensor T=(_l=1^length(w) wl*Ail*Bjl*Ckl)_ijk. \n\n\n\n\n\n","category":"function"},{"location":"code/0.tensors/","page":"Tensors","title":"Tensors","text":"multilinear\napolarpro\nnorm_apolar","category":"page"},{"location":"code/0.tensors/#TensorDec.multilinear","page":"Tensors","title":"TensorDec.multilinear","text":"multilinear(T, X, Y, Z) -> Polynomial{true,C}\n\nCompute the multilinear polynomial T=(_ijk Tijk*Xi*Yj*Zk. \n\n\n\n\n\n","category":"function"},{"location":"code/0.tensors/#TensorDec.apolarpro","page":"Tensors","title":"TensorDec.apolarpro","text":"apolarpro(P,Q) -> ComplexF64\n\nThe apolar product of two homogeneous polynomials P=∑{|α|=d} binom{d}{α} pα x^α and Q=∑{|α|=d} binom{d}{α} qα  x^α, of degree d in n variables is given by ⟨P,Q⟩d=∑{|α|=d} binom{d}{α}̅conj(pα) qα.\n\nExample\n\njulia> X= @polyvar x1 x2\n2-element Array{PolyVar{true},1}:\n x1\n x2\n\njulia> P=x1^2+2*im*x1*x2+x2^2\nx1² + (0 + 2im)x1x2 + x2²\n\njulia> Q=2*x1^2+3*x1*x2+6x2^2\n2x1² + 3x1x2 + 6x2²\n\njulia> apolarpro(P,Q)\n8.0 - 3.0im\n\n\n\n\n\n","category":"function"},{"location":"code/0.tensors/#TensorDec.norm_apolar","page":"Tensors","title":"TensorDec.norm_apolar","text":"norm_apolar(P) -> Float64\n\nGives the apolar norm of a homogeneous polynomial P=∑{|α|=d} binom{d}{α} pα x^α as: normapolar(P)=∑{|α|=d} binom{d}{α} pα*̄pα.\n\n```\n\n\n\n\n\n","category":"function"},{"location":"expl/7.Phylogenetic/#Phylogenetic-trees","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"","category":"section"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"using TensorDec\nnormalize_markov! = function(w,A,B,C) \n    for i in 1:size(A,2) \n        l = sum(A[j,i] for j in 1:size(A,1) ) \n        A[:,i] /= l\n        w[i] *= l\n    end\n    for i in 1:size(B,2) \n        l = sum(B[j,i] for j in 1:size(B,1) ) \n        B[:,i] /=l\n        w[i] *= l\n    end\n    for i in 1:size(C,2) \n        l = sum(C[j,i] for j in 1:size(B,1) ) \n        C[:,i] /=l\n        w[i] *= l\n    end\n    w, A,B,C\nend","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"#3 (generic function with 1 method)","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"A = rand(4,4); B = rand(4,4); C = rand(4,4); w = rand(4);\nnormalize_markov!(w,A,B,C)\nfill(1.,4)'*A, fill(1.,4)'*B, fill(1.,4)'*C","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"([1.0 1.0 1.0 1.0], [1.0 1.0 1.0 1.0], [1.0 1.0 1.0 1.0])","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"t = tensor(w,A,B,C)","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"4×4×4 Array{Float64,3}:\n[:, :, 1] =\n 0.22132   0.166737  0.254042  0.0613668\n 0.092515  0.112218  0.194429  0.0814187\n 0.316227  0.225333  0.297283  0.0668594\n 0.309741  0.261594  0.293648  0.110342 \n\n[:, :, 2] =\n 0.0403731  0.0268474  0.0398125  0.0135116\n 0.024117   0.0254106  0.0371     0.0226149\n 0.0546752  0.0364448  0.0452751  0.0139016\n 0.0583531  0.0540776  0.051944   0.0289579\n\n[:, :, 3] =\n 0.15016    0.0921238  0.133752  0.0523025\n 0.0810969  0.0689567  0.112981  0.0703695\n 0.196223   0.121267   0.146411  0.0483899\n 0.180559   0.144179   0.137036  0.0674456\n\n[:, :, 4] =\n 0.119343   0.11672   0.22974   0.0601882\n 0.0967337  0.124609  0.217909  0.0854228\n 0.146758   0.136596  0.242653  0.0650576\n 0.168666   0.191626  0.252545  0.11588","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"wd, Ad, Bd, Cd = decompose(t)\nnormalize_markov!(wd,Ad,Bd,Cd)","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"MethodError: no method matching decompose(::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::getfield(MultivariateSeries, Symbol(\"##25#27\")){Float64})\nClosest candidates are:\n  decompose(::Array{Array{C,2},1}, !Matched::Function) where C at /Users/mourrain/.julia/packages/MultivariateSeries/mJQLE/src/decompose.jl:20\n  decompose(!Matched::DynamicPolynomials.Polynomial{true,C}, !Matched::Function, ::Any) where C at /Users/mourrain/Julia/TensorDec.jl/src/decompose.jl:22\n\n\n\nStacktrace:\n\n [1] #decompose#23(::Int64, ::Function, ::Array{Float64,3}, ::Function) at /Users/mourrain/Julia/TensorDec.jl/src/decompose.jl:215\n\n [2] decompose(::Array{Float64,3}, ::Function) at /Users/mourrain/Julia/TensorDec.jl/src/decompose.jl:210 (repeats 2 times)\n\n [3] top-level scope at In[4]:1","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"w","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"4-element Array{Float64,1}:\n 1.3184908145711505\n 1.1386144184166538\n 2.8433075891450534\n 2.5117767986101014","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"wd","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"UndefVarError: wd not defined\n\n\n\nStacktrace:\n\n [1] top-level scope at In[6]:1","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"A","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"4×4 Array{Float64,2}:\n 0.0135068  0.32004   0.275579  0.243881   \n 0.299151   0.323187  0.240813  0.000311288\n 0.063392   0.252418  0.271949  0.404148   \n 0.62395    0.104355  0.211659  0.35166","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"Ad","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"UndefVarError: Ad not defined\n\n\n\nStacktrace:\n\n [1] top-level scope at In[8]:1","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"using LinearAlgebra\nnorm(t-tensor(wd,Ad,Bd,Cd))","category":"page"},{"location":"expl/7.Phylogenetic/","page":"Phylogenetic trees","title":"Phylogenetic trees","text":"UndefVarError: wd not defined\n\n\n\nStacktrace:\n\n [1] top-level scope at In[9]:2","category":"page"},{"location":"#TensorDec","page":"Home","title":"TensorDec","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Package for the decomposition of tensors and polynomial-exponential series.","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package TensorDec.jl provides tools for the following decomposition problems:","category":"page"},{"location":"#Symmetric-tensor-decomposition","page":"Home","title":"Symmetric tensor decomposition","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For symmetric tensors or multivariate homogeneous polynomials sigma(mathbfx) = sum_alpha=d sigma_alpha d choose alpha mathbfx^alpha, we consider their Waring decomposition:","category":"page"},{"location":"","page":"Home","title":"Home","text":"    sigma(mathbfx) = sum_i=1^r omega_i (xi_i1 x_1+ cdots + xi_in x_n)^d","category":"page"},{"location":"","page":"Home","title":"Home","text":"with r minimal.","category":"page"},{"location":"#Multilinear-tensor-decomposition","page":"Home","title":"Multilinear tensor decomposition","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For multilinear tensors, sigma=(sigma_ijk)in E_1 otimes E_2 otimes E_3 we consider the decomposition:","category":"page"},{"location":"","page":"Home","title":"Home","text":"    sigma = sum_i=1^r omega_i U_i^1 otimes U_i^2 otimes U_i^3","category":"page"},{"location":"","page":"Home","title":"Home","text":"with U_i^j in E_j vectors and r minimal.","category":"page"},{"location":"#sec_examples","page":"Home","title":"Tutorials","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = map(file -> joinpath(\"expl\", file), filter(x ->endswith(x, \"md\"), readdir(\"expl\")))","category":"page"},{"location":"#Manual","page":"Home","title":"Manual","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = map(file -> joinpath(\"code\", file), filter(x ->endswith(x, \"md\"), readdir(\"code\"))) ","category":"page"},{"location":"#sec_installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package is available at https://github.com/AlgebraicGeometricModeling/TensorDec.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To install it from Julia:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add https://github.com/AlgebraicGeometricModeling/TensorDec.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"It can then be used as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TensorDec","category":"page"},{"location":"","page":"Home","title":"Home","text":"For more details, see the tutorials","category":"page"},{"location":"#Dependencies","page":"Home","title":"Dependencies","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package TensorDec depends on the following packages:","category":"page"},{"location":"","page":"Home","title":"Home","text":"LinearAlgebra standard package for linear algebra.\nDynamicPolynomials package on multivariate polynomials represented as lists of monomials.\nMultivariatePolynomials generic interface package for multivariate polynomials.\nMultivariateSeries for duality on multivariate polynomials.","category":"page"},{"location":"","page":"Home","title":"Home","text":"These packages are installed with TensorDec  (see installation).","category":"page"}]
}
