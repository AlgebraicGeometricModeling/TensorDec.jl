
# Multilinear tensors


```julia
using TensorDec
```

We consider a multi-linear tensor of size 3 x 5 x 4, which is sum of r=4 tensor products of the random column vectors of the matrices `A0`, `B0`, `C0`with weights `w0`:


```julia
r=4
w0 = rand(r)
A0 = rand(3,r)
B0 = rand(5,r)
C0 = rand(4,r)

T0 = tensor(w0, A0, B0, C0)
```




    3×5×4 Array{Float64, 3}:
    [:, :, 1] =
     0.316184  0.345023   0.382037  0.36165   0.486526
     0.404335  0.276629   0.434605  0.344533  0.509244
     0.111832  0.0641309  0.111185  0.103334  0.11392
    
    [:, :, 2] =
     0.353912  0.447882  0.428276  0.478536  0.565683
     0.491082  0.387773  0.529839  0.517911  0.582768
     0.175713  0.117616  0.188383  0.200218  0.146661
    
    [:, :, 3] =
     0.234157  0.189894   0.277909  0.200739  0.326495
     0.333178  0.184865   0.373708  0.241155  0.376656
     0.104873  0.0597654  0.117054  0.100222  0.088638
    
    [:, :, 4] =
     0.372136  0.0808872  0.301894   0.187236   0.398308
     0.499487  0.093278   0.399356   0.240435   0.524856
     0.126637  0.0208347  0.0864272  0.0717313  0.127397



We compute its decomposition:


```julia
w, A, B, C = decompose(T0);
```

We obtain a decomposition of rank 4 with weights:


```julia
w
```




    4-element Vector{Float64}:
     0.33792668673343457
     0.7408084924294192
     0.9605854249810668
     1.0267280992544108



The r=4 vectors of norm 1 of the first components of the decomposition are the columns of the matrix A:  


```julia
A
```




    3×4 Matrix{Float64}:
     0.0808627  0.576234  0.590579  0.831589
     0.744569   0.778708  0.794381  0.548351
     0.66263    0.248132  0.142043  0.0881477



The r=4 vectors  of norm 1 of the second components are the columns of the matrix B: 


```julia
B
```




    5×4 Matrix{Float64}:
     0.414404  0.624532   0.503332   -0.136551
     0.334042  0.0598829  0.108848   -0.615309
     0.571347  0.233124   0.623258   -0.335895
     0.607836  0.469743   0.0629459  -0.52911
     0.144163  0.575646   0.585147   -0.458221



The r=4 vectors of norm 1 of the third components are the columns of the matrix C:


```julia
C
```




    4×4 adjoint(::Matrix{Float64}) with eltype Float64:
     0.273397   0.39815   0.489947  -0.575025
     0.84564    0.521266  0.407014  -0.764628
     0.458126   0.232774  0.467259  -0.287248
     0.0163813  0.718035  0.613156  -0.0466739



It corresponds to the tensor $\sum_{i=1}^{r} w_i \, A[:,i] \otimes B[:,i] \otimes C[:,i]$ for $i \in 1:r$:


```julia
T = tensor(w, A, B, C)
```




    3×5×4 Array{Float64, 3}:
    [:, :, 1] =
     0.316184  0.345023   0.382037  0.36165   0.486526
     0.404335  0.276629   0.434605  0.344533  0.509244
     0.111832  0.0641309  0.111185  0.103334  0.11392
    
    [:, :, 2] =
     0.353912  0.447882  0.428276  0.478536  0.565683
     0.491082  0.387773  0.529839  0.517911  0.582768
     0.175713  0.117616  0.188383  0.200218  0.146661
    
    [:, :, 3] =
     0.234157  0.189894   0.277909  0.200739  0.326495
     0.333178  0.184865   0.373708  0.241155  0.376656
     0.104873  0.0597654  0.117054  0.100222  0.088638
    
    [:, :, 4] =
     0.372136  0.0808872  0.301894   0.187236   0.398308
     0.499487  0.093278   0.399356   0.240435   0.524856
     0.126637  0.0208347  0.0864272  0.0717313  0.127397



We compute the $L^2$ norm of the difference between $T$ and $T_0$:


```julia
using LinearAlgebra
norm(T-T0)
```




    5.414241769776905e-15


