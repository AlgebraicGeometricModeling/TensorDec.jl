
# Multilinear tensors


```julia
using TensorDec
```

We consider a multi-linear tensor of size 3 x 5 x 4, which is sum of r=4 tensor products of the random column vectors of the matrices `A0`, `B0`, `C0`with weights `w0`:


```julia
r=4
w0 = rand(r)
A0 = rand(3,r)
B0 = rand(5,r)
C0 = rand(4,r)

T0 = tensor(w0, A0, B0, C0)
```




    3×5×4 Array{Float64,3}:
    [:, :, 1] =
     0.319429  0.635469  0.448748  0.153548  0.442585
     0.317151  0.557379  0.416863  0.111633  0.453205
     0.230556  0.503791  0.34481   0.138007  0.335045
    
    [:, :, 2] =
     0.21308   0.23879   0.193367  0.0393124  0.211802
     0.195158  0.232615  0.186988  0.0398447  0.209756
     0.12532   0.153443  0.119337  0.0332111  0.131272
    
    [:, :, 3] =
     0.25598   0.582839  0.382755  0.205059  0.393088
     0.303116  0.571735  0.388197  0.214855  0.454079
     0.239338  0.522709  0.320508  0.249643  0.347097
    
    [:, :, 4] =
     0.188868  0.213582  0.157138  0.0749168  0.179161
     0.173962  0.192918  0.133923  0.0945415  0.16767 
     0.135026  0.167918  0.104803  0.104118   0.132515



We compute its decomposition:


```julia
w, A, B, C = decompose(T0);
```

We obtain a decomposition of rank 4 with weights:


```julia
w
```




    4-element Array{Float64,1}:
     0.3224222686073423
     1.1691009516673598
     0.7305863382940503
     0.5968718066692266



The r=4 vectors of norm 1 of the first components of the decomposition are the columns of the matrix A:  


```julia
A
```




    3×4 Array{Float64,2}:
     0.374571  0.495746  0.725665  0.723733
     0.619727  0.786126  0.217038  0.576062
     0.689663  0.369109  0.65292   0.379951



The r=4 vectors  of norm 1 of the second components are the columns of the matrix B: 


```julia
B
```




    5×4 Array{Float64,2}:
     -0.364084  0.315586   -0.201537  0.579243 
     -0.444107  0.618725   -0.751433  0.493687 
     -0.113996  0.474263   -0.457669  0.432602 
     -0.737864  0.0934078  -0.249374  0.0532333
     -0.335818  0.532854   -0.350834  0.480388 



The r=4 vectors of norm 1 of the third components are the columns of the matrix C:


```julia
C
```




    4×4 Adjoint{Float64,Array{Float64,2}}:
     -0.112192   0.674727   -0.73096    0.451539 
     -0.0624781  0.183315   -0.06187    0.680176 
     -0.854461   0.711642   -0.67229    0.0655968
     -0.503394   0.0685937  -0.0994776  0.573733 



It corresponds to the tensor $\sum_{i=1}^{r} w_i \, A[:,i] \otimes B[:,i] \otimes C[:,i]$ for $i \in 1:r$:


```julia
T = tensor(w, A, B, C)
```




    3×5×4 Array{Float64,3}:
    [:, :, 1] =
     0.319429  0.635469  0.448748  0.153548  0.442585
     0.317151  0.557379  0.416863  0.111633  0.453205
     0.230556  0.503791  0.34481   0.138007  0.335045
    
    [:, :, 2] =
     0.21308   0.23879   0.193367  0.0393124  0.211802
     0.195158  0.232615  0.186988  0.0398447  0.209756
     0.12532   0.153443  0.119337  0.0332111  0.131272
    
    [:, :, 3] =
     0.25598   0.582839  0.382755  0.205059  0.393088
     0.303116  0.571735  0.388197  0.214855  0.454079
     0.239338  0.522709  0.320508  0.249643  0.347097
    
    [:, :, 4] =
     0.188868  0.213582  0.157138  0.0749168  0.179161
     0.173962  0.192918  0.133923  0.0945415  0.16767 
     0.135026  0.167918  0.104803  0.104118   0.132515



We compute the $L^2$ norm of the difference between $T$ and $T_0$:


```julia
using LinearAlgebra
norm(T-T0)
```




    1.0024742282590783e-14


