<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Decomposition · TensorDec</title><meta name="title" content="Decomposition · TensorDec"/><meta property="og:title" content="Decomposition · TensorDec"/><meta property="twitter:title" content="Decomposition · TensorDec"/><meta name="description" content="Documentation for TensorDec."/><meta property="og:description" content="Documentation for TensorDec."/><meta property="twitter:description" content="Documentation for TensorDec."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TensorDec</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../expl/0.Decomposition/">Decomposition algorithm</a></li><li><a class="tocitem" href="../../expl/1.SymmetricTensor/">Symmetric tensors</a></li><li><a class="tocitem" href="../../expl/2.MultilinearTensor/">Multilinear tensors</a></li><li><a class="tocitem" href="../../expl/7.Phylogenetic/">Phylogenetic trees</a></li><li><a class="tocitem" href="../../expl/8.1.Sym_rank_one_approx/">Best rank one approximation and optimization on the sphere</a></li><li><a class="tocitem" href="../../expl/8.2.Sym_rank_approx/">Low rank approximation of symmetric tensors</a></li><li><a class="tocitem" href="../../expl/9.SphericalGaussianMixture/">Decomposition of a mixture of spherical Gaussians</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../0.tensors/">Tensors</a></li><li><a class="tocitem" href="../1.series/">Series</a></li><li><a class="tocitem" href="../2.polynomials/">Polynomials</a></li><li class="is-active"><a class="tocitem" href>Decomposition</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Decomposition</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Decomposition</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/master/docs/mrkd/code/3.decompose.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Decomposition"><a class="docs-heading-anchor" href="#Decomposition">Decomposition</a><a id="Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Decomposition" title="Permalink"></a></h1><ul><li><a href="#MultivariateSeries.decompose"><code>MultivariateSeries.decompose</code></a></li><li><a href="#TensorDec.approximate"><code>TensorDec.approximate</code></a></li><li><a href="#TensorDec.rcg_decompose"><code>TensorDec.rcg_decompose</code></a></li><li><a href="#TensorDec.rgn_v_tr"><code>TensorDec.rgn_v_tr</code></a></li><li><a href="#TensorDec.rne_n_tr"><code>TensorDec.rne_n_tr</code></a></li><li><a href="#TensorDec.rne_n_tr_r"><code>TensorDec.rne_n_tr_r</code></a></li><li><a href="#TensorDec.spm_decompose"><code>TensorDec.spm_decompose</code></a></li><li><a href="#TensorDec.tensorsplit"><code>TensorDec.tensorsplit</code></a></li><li><a href="#TensorDec.weights"><code>TensorDec.weights</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MultivariateSeries.decompose" href="#MultivariateSeries.decompose"><code>MultivariateSeries.decompose</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">decompose(p :: DynamicPolynomials.Polynomial,  rkf :: Function)</code></pre><p>Decompose the homogeneous polynomial <span>$p$</span> as <span>$∑ ω_i (ξ_{i1} x_1 + ... + ξ_{in} x_n)ᵈ$</span> where <span>$d$</span> is the degree of <span>$p$</span>.</p><p>The optional argument <code>rkf</code> is the rank function used to determine the numerical rank from the vector S of singular values. Its default value <code>eps_rkf(1.e-6)</code> determines the rank as the first i s.t. S[i+1]/S[i]&lt; 1.e-6 where S is the vector of singular values.</p><p>If the rank function <code>cst_rkf(r)</code> is used, the SVD is truncated at rank r.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/decompose.jl#L12-L21">source</a></section><section><div><pre><code class="language-julia hljs">decompose(T :: Array{C,3},  rkf :: Function)</code></pre><p>Decompose the multilinear tensor <code>T</code> of order 3 as a weighted sum of tensor products of vectors of norm 1.</p><p>The optional argument <code>rkf</code> is the rank function used to determine the numerical rank from the vector S of singular values. Its default value <code>eps_rkf(1.e-6)</code> determines the rank as the first i s.t. S[i+1]/S[i]&lt; 1.e-6 where S is the vector of singular values.</p><p>If the rank function cst_rkf(r) is used, the SVD is truncated at rank r.</p><p>Slices along the mode m=1 of the tensor (i.e. <code>T[i,:,:]</code>) are used by default to compute the decomposition. The optional argument <code>mode = m</code> can be used to specify the sliced mode.</p><pre><code class="nohighlight hljs">decompose(T, mode=2)
decompose(T, eps_rkf(1.e-10), mode=3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/decompose.jl#L201-L216">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.spm_decompose" href="#TensorDec.spm_decompose"><code>TensorDec.spm_decompose</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">spm_decompose(T, r::Int64, v0::Vector)</code></pre><p>Decomposition of the tensor T in rank r with the Power Method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/spm.jl#L95-L101">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.rcg_decompose" href="#TensorDec.rcg_decompose"><code>TensorDec.rcg_decompose</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">rcg_decompose(p :: Polynomial{true,T},  rkf :: Function)</code></pre><p>Decompose the homogeneous polynomial <span>$p$</span> as <span>$∑ ω_i (ξ_{i1} x_1 + ... + ξ_{in} x_n)ᵈ$</span> where <span>$d$</span> is the degree of <span>$p$</span>.</p><p>The optional argument <code>rkf</code> is the rank function used to determine the numerical rank from the vector S of singular values. Its default value <code>eps_rkf(1.e-6)</code> determines the rank as the first i s.t. S[i+1]/S[i]&lt; 1.e-6 where S is the vector of singular values.</p><p>If the rank function <code>cst_rkf(r)</code> is used, the SVD is truncated at rank r.</p><p>A Riemannian conjugate gradient algorithm is used (RCG) in the algorithm decompose (rcg_decompose) to approximate the pencil of submatrices of the Hankel matrix by a pencil of real simultaneous diagonalizable matrices.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/rcg_decompose.jl#L9-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.tensorsplit" href="#TensorDec.tensorsplit"><code>TensorDec.tensorsplit</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Decompose V as <span>$u \otimes v$</span> where u is of dimension n1 and v of dimension n2.</p><p>It is based on the svd decomposition of the <span>$n1 \times n2$</span> matrix associated to <code>V</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/multilinear.jl#L83-L87">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.approximate" href="#TensorDec.approximate"><code>TensorDec.approximate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">approximate(P::Polynomial, r:: Int64; iter = :RNE, init = :Random)</code></pre><p>This function approximates a symmetric tensor (real or complex valued) into a low rank symmetric tensor.</p><p>Input:</p><ul><li>P: The homogeneous polynomial associated to the symmetric tensor to approximate.</li><li>r: Approximation rank.</li></ul><p>The option <code>iter</code> specifies the method to apply in order to find the approximation, there are 4 options (the default is rne<em>n</em>tr):</p><pre><code class="nohighlight hljs"> * RNE: To apply the function &#39;rne_n_tr&#39;: This function gives a low symmetric rank approximation of a complex valued
 symmetric tensor by applying an exact Riemannian Newton iteration with
 dog-leg trust region steps to the associate non-linear-least-squares
 problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form
 of linear combination of r linear forms to the d-th power ``∑w_i*(v_i^tx)^d`` with i=1,...,r.
 This approximation is represented by a vector of strictly positive real numbers W=(w_i) (weight vector), and a matrix of normalized columns V=[v_1;...;v_r];

 * RNER: To apply the function &#39;rne_n_tr_r&#39;(when the symmetric tensor is real and the symmetric tensor approximation is required to be real): This function gives a low symmetric rank approximation of a real valued
 symmetric tensor by applying an exact Riemannian Newton iteration with
 dog-leg trust region steps to the associate non-linear-least-squares
 problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form
 of linear combination of r linear forms to the d-th power ∑w_i*(v_i^tx)^d, with i=1,...,r.
 This approximation is represented by a vector of r real numbers W=(w_i) (weight vector), and a matrix
 of real normalized columns V=[v_1;...;v_r];

 * RGN: To apply the function &#39;rgn_v_tr&#39;: This function gives a low symmetric rank approximation of a complex valued
 symmetric tensor by applying a Riemannian Gauss-Newton iteration with
 dog-leg trust region steps to the associate non-linear-least-squares
 problem. The optimization set is a cartesian product of Veronese
 manifolds. The approximation is of the form
 of linear combination of r linear forms to the d-th power ∑(v_i^tx)^d, with i=1,...,r.
 This approximation is represented by a matrix [v_1;...;v_r];

 * SPM: To apply the function &#39;spm_decompose&#39;: Decomposition of the tensorwith the Power Method.</code></pre><p>The option <code>init</code> specifies the way the initial point for the first three methods is chosen by the function decompose:</p><pre><code class="nohighlight hljs"> * Random: To choose a random combination (default option);
 * Rnd: To choose non-random combination.
 *RCG: To choose to approximate the pencil of submatrices of the Hankel matrix by a pencil of real simultaneous diagonalizable matrices using Riemannian conjugate gradient algorithm.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/approximate.jl#L9-L53">source</a></section><section><div><pre><code class="language-julia hljs">approximate(P::Polynomial, w0, V0; iter = :RNE, init = :Random)</code></pre><p>This function approximates a symmetric tensor (real or complex valued) into a low rank symmetric tensor starting from an initial decomposition (w0, V0)</p><p>Input:</p><ul><li>P: The homogeneous polynomial associated to the symmetric tensor to approximate.</li><li>w0: Initial weights of the decomposition</li><li>V0: Initial vectors of the decomposition</li></ul><p>The option <code>iter</code> specifies the method to apply in order to find the approximation, there are 4 options (the default is :RNE):</p><pre><code class="nohighlight hljs"> * RNE: To apply the function &#39;rne_n_tr&#39;: This function gives a low symmetric rank approximation of a complex valued
 symmetric tensor by applying an exact Riemannian Newton iteration with
 dog-leg trust region steps to the associate non-linear-least-squares
 problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form
 of linear combination of r linear forms to the d-th power ``∑w_i*(v_i^tx)^d`` with i=1,...,r.
 This approximation is represented by a vector of strictly positive real numbers W=(w_i) (weight vector), and a matrix of normalized columns V=[v_1;...;v_r];

 * RNER: To apply the function &#39;rne_n_tr_r&#39;(when the symmetric tensor is real and the symmetric tensor approximation is required to be real): This function gives a low symmetric rank approximation of a real valued
 symmetric tensor by applying an exact Riemannian Newton iteration with
 dog-leg trust region steps to the associate non-linear-least-squares
 problem. The optimization set is parameterized by weights and unit vectors. The approximation is of the form
 of linear combination of r linear forms to the d-th power ∑w_i*(v_i^tx)^d, with i=1,...,r.
 This approximation is represented by a vector of r real numbers W=(w_i) (weight vector), and a matrix
 of real normalized columns V=[v_1;...;v_r];

 * RGN: To apply the function &#39;rgn_v_tr&#39;: This function gives a low symmetric rank approximation of a complex valued
 symmetric tensor by applying a Riemannian Gauss-Newton iteration with
 dog-leg trust region steps to the associate non-linear-least-squares
 problem. The optimization set is a cartesian product of Veronese
 manifolds. The approximation is of the form
 of linear combination of r linear forms to the d-th power ∑(v_i^tx)^d, with i=1,...,r.
 This approximation is represented by a matrix [v_1;...;v_r];

 * SPM: To apply the function &#39;spm_decompose&#39;: Decomposition of the tensorwith the Power Method.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/approximate.jl#L96-L136">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.rne_n_tr" href="#TensorDec.rne_n_tr"><code>TensorDec.rne_n_tr</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">rne_n_tr(P, A0, B0, Dict{String,Any}(&quot;maxIter&quot; =&gt; N,&quot;epsIter&quot; =&gt; ϵ))⤍ A, B, Info</code></pre><p>This function gives a low symmetric rank approximation of a complex valued symmetric tensor by applying an exact Riemannian Newton iteration with dog-leg trust region steps to the associate non-linear-least-squares problem. The optimization set is parameterized by weights and unit vectors. Let r be the approximation rank. The approximation is of the form of linear combination of r linear forms to the d-th power <span>$∑w_i*(v_i^tx)^d$</span> with i=1,...,r. This approximation is represented by a vector of strictly positive real numbers W=(w<em>i) (weight vector), and a matrix of normalized columns V=[v</em>1;...;v_r].</p><p>Input:</p><ul><li>P: Homogeneous polynomial (associated to the symmetric tensor to approximate).</li><li>A0: Initial weight vector of size equal to the approximation rank.</li><li>B0: Initial matrix of row size equal to the dimension of P and column size equal to the  approximation rank.</li><li>N: Maximal number of iterations (by default 500).</li><li>ϵ: The radius of the trust region (by default 1.e-3).</li></ul><p>Output:</p><ul><li>A: Weight vector of size equal to the approximation rank. It is a real strictly positive vector.</li><li>B: Matrix of row size equal to the dimension of P and column size equal to the approximation rank. The columns vectors of B are normalized.</li><li>Info: &#39;d0&#39; (resp. &#39;d*&#39;) represents the initial (resp. the final) residual error,    &#39;nIter&#39; is for the number of iterations needed to find the approximation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/RNE_N_TR.jl#L180-L207">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.rne_n_tr_r" href="#TensorDec.rne_n_tr_r"><code>TensorDec.rne_n_tr_r</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">rne_n_tr_r(P, A0, B0, Dict{String,Any}(&quot;maxIter&quot; =&gt; N,&quot;epsIter&quot; =&gt; ϵ))⤍ A, B, Info</code></pre><p>This function gives a low symmetric rank approximation of a real valued symmetric tensor by applying an exact Riemannian Newton iteration with dog-leg trust region steps to the associate non-linear-least-squares problem. The optimization set is parameterized by weights and unit vectors. Let r be the approximation rank. The approximation is of the form of linear combination of r linear forms to the d-th power ∑w<em>i*(v</em>i^tx)^d, with i=1,...,r. This approximation is represented by a vector of r real numbers W=(w<em>i) (weight vector), and a matrix of normalized columns V=[v</em>1;...;v_r].</p><p>Input:</p><ul><li>P: Homogeneous polynomial (associated to the symmetric tensor to approximate).</li><li>A0: Initial weight vector of size equal to the approximation rank.</li><li>B0: Initial matrix of row size equal to the dimension of P and column size equal to the  approximation rank.</li></ul><p>The options are</p><ul><li>N: Maximal number of iterations (by default 500).</li><li>ϵ: The radius of the trust region (by default 1.e-3).</li></ul><p>Output:</p><ul><li>A: Weight vector of size equal to the approximation rank.</li><li>B: Matrix of row size equal to the dimension of P and column size equal to the</li></ul><p>approximation rank. The columns vectors of B are normalized.</p><ul><li>Info: &#39;d0&#39; (resp. &#39;d*&#39;) represents the initial (resp. the final) residual error,   &#39;nIter&#39; is for the number of iterations needed to find the approximation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/RNE_N_TR_R.jl#L187-L217">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.rgn_v_tr" href="#TensorDec.rgn_v_tr"><code>TensorDec.rgn_v_tr</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">    rgn_v_tr(P, B0, Dict{String,Any}(&quot;maxIter&quot; =&gt; N,&quot;epsIter&quot; =&gt; ϵ))⤍ B, Info</code></pre><p>This function gives a low symmetric rank approximation of a complex valued symmetric tensor by applying a Riemannian Gauss-Newton iteration with dog-leg trust region steps to the associate non-linear-least-squares problem. The optimization set is a cartesian product of Veronese manifolds. Let r be the approximation rank. The approximation is of the form of linear combination of r linear forms to the d-th power ∑(v<em>i^tx)^d, with i=1,...,r. This approximation is represented by a matrix [v</em>1;...;v_r].</p><p>Input:</p><ul><li>P: Homogeneous polynomial (associated to the symmetric tensor to approximate).</li><li>B0: Matrix of row size equal to the dimension of P and column size equal to the     approximation rank (initial point).</li><li>N: Maximal number of iterations (by default 500).</li><li>ϵ: The radius of the trust region (by default 1.e-3).</li></ul><p>Output:</p><ul><li>B: Matrix of row size equal to the dimension of P and column size equal to the approximation rank. This matrix contains the r vectors of the symmetric decomposition of the approximation.</li><li>Info: &#39;d0&#39; (resp. &#39;d*&#39;) represents the initial (resp. the final) residual error,       &#39;nIter&#39; is for the number of iterations needed to find the approximation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/RGN_V_TR.jl#L209-L234">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorDec.weights" href="#TensorDec.weights"><code>TensorDec.weights</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">weights(T, Xi::Matrix) -&gt; Vector</code></pre><p>Compute the weight vector in the decomposition of the homogeneous polynomial <code>T</code> as a weighted sum of powers of the linear forms associated to the columns of <code>Xi</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AlgebraicGeometricModeling/TensorDec.jl/blob/8ef3d493f75ca30c34fb34d5fb93f09753e2e102/src/decompose.jl#L254-L261">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../2.polynomials/">« Polynomials</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Tuesday 23 April 2024 15:37">Tuesday 23 April 2024</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
